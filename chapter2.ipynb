{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanw/eodp-companion/blob/main/chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.3 Jacobians\n",
        "\n",
        "To compute the Jacobian of a function using Python, we'll use the `sympy` library, which provides tools for symbolic mathematics. The Jacobian matrix represents the first-order partial derivatives of a vector-valued function. It's particularly useful for understanding the behavior of multivariate functions.\n",
        "\n",
        "Let's say we have a function $ f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2 $ defined by:\n",
        "$ f(w) = \\begin{bmatrix} f_1(w) \\\\ f_2(w) \\end{bmatrix} = \\begin{bmatrix} w_1^2 + w_2^2 \\\\ e^{w_1} + w_2 \\end{bmatrix} $\n",
        "where $ w = (w_1, w_2) $ is the input vector.\n",
        "\n",
        "The Jacobian matrix $ J $ of $ f $ at any point $ w $ is given by:\n",
        "$ J(f)(w) = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial w_1} & \\frac{\\partial f_1}{\\partial w_2} \\\\ \\frac{\\partial f_2}{\\partial w_1} & \\frac{\\partial f_2}{\\partial w_2} \\end{bmatrix} $\n",
        "\n",
        "Here's how you can compute the Jacobian using `sympy`:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FqtBi-trvao-"
      },
      "outputs": [
        {
          "data": {
            "text/latex": [
              "$\\displaystyle \\left[\\begin{matrix}2 w_{1} & 2 w_{2}\\\\e^{w_{1}} & 1\\end{matrix}\\right]$"
            ],
            "text/plain": [
              "Matrix([\n",
              "[   2*w1, 2*w2],\n",
              "[exp(w1),    1]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#2.2.3\n",
        "import sympy as sp\n",
        "\n",
        "# Define symbols\n",
        "w1, w2 = sp.symbols('w1 w2')\n",
        "\n",
        "# Define the function f(w) = [f1(w), f2(w)]\n",
        "f1 = w1**2 + w2**2\n",
        "f2 = sp.exp(w1) + w2\n",
        "\n",
        "# Construct the vector function\n",
        "f = sp.Matrix([f1, f2])\n",
        "\n",
        "# Define the input vector\n",
        "w = sp.Matrix([w1, w2])\n",
        "\n",
        "# Compute the Jacobian\n",
        "J = f.jacobian(w)\n",
        "\n",
        "# Display the Jacobian\n",
        "J\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This code snippet defines the symbols $ w_1 $ and $ w_2 $, constructs the vector-valued function $ f $, and then computes the Jacobian matrix of $ f $ with respect to the input vector $ w $. The result, `J`, is the Jacobian matrix that consists of the partial derivatives of $ f_1 $ and $ f_2 $ with respect to $ w_1 $ and $ w_2 $. Let's run this example and see the output.\n",
        "\n",
        "The Jacobian matrix of the function $ f $ with respect to the input vector $ w = (w_1, w_2) $ is:\n",
        "$ J(f)(w) = \\begin{bmatrix} 2w_1 & 2w_2 \\\\ e^{w_1} & 1 \\end{bmatrix} $\n",
        "\n",
        "This matrix represents the first-order partial derivatives of the components of $ f $ with respect to each of the input variables $ w_1 $ and $ w_2 $, providing a linear approximation of the function's behavior around any point $ w $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's consider a function $ f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^3 $ with three input variables, defined as:\n",
        "$ f(w) = \\begin{bmatrix} f_1(w) \\\\ f_2(w) \\\\ f_3(w) \\end{bmatrix} = \\begin{bmatrix} w_1^2 + w_2^2 + w_3^2 \\\\ e^{w_1} + \\sin(w_2) + w_3 \\\\ w_1 \\cdot w_2 + \\ln(w_3 + 1) \\end{bmatrix} $\n",
        "where $ w = (w_1, w_2, w_3) $ is the input vector.\n",
        "\n",
        "The Jacobian matrix $ J $ of $ f $ at any point $ w $ is given by the matrix of all first-order partial derivatives of each component of $ f $ with respect to each of the input variables $ w_1, w_2, $ and $ w_3 $:\n",
        "$ J(f)(w) = \\begin{bmatrix} \\frac{\\partial f_1}{\\partial w_1} & \\frac{\\partial f_1}{\\partial w_2} & \\frac{\\partial f_1}{\\partial w_3} \\\\ \\frac{\\partial f_2}{\\partial w_1} & \\frac{\\partial f_2}{\\partial w_2} & \\frac{\\partial f_2}{\\partial w_3} \\\\ \\frac{\\partial f_3}{\\partial w_1} & \\frac{\\partial f_3}{\\partial w_2} & \\frac{\\partial f_3}{\\partial w_3} \\end{bmatrix} $\n",
        "\n",
        "Let's compute this Jacobian matrix using `sympy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define symbols\n",
        "w1, w2, w3 = sp.symbols('w1 w2 w3')\n",
        "\n",
        "# Define the function f(w) = [f1(w), f2(w), f3(w)]\n",
        "f1 = w1**2 + w2**2 + w3**2\n",
        "f2 = sp.exp(w1) + sp.sin(w2) + w3\n",
        "f3 = w1*w2 + sp.log(w3 + 1)\n",
        "\n",
        "# Construct the vector function\n",
        "f = sp.Matrix([f1, f2, f3])\n",
        "\n",
        "# Define the input vector\n",
        "w = sp.Matrix([w1, w2, w3])\n",
        "\n",
        "# Compute the Jacobian\n",
        "J = f.jacobian(w)\n",
        "\n",
        "# Display the Jacobian\n",
        "J"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code snippet will compute the Jacobian matrix of the given function $ f $ with respect to the inputs $ w_1, w_2, $ and $ w_3 $. Let's execute it to see the matrix.\n",
        "\n",
        "The Jacobian matrix of the function $ f $ with three input variables $ w = (w_1, w_2, w_3) $ is:\n",
        "$ J(f)(w) = \\begin{bmatrix} 2w_1 & 2w_2 & 2w_3 \\\\ e^{w_1} & \\cos(w_2) & 1 \\\\ w_2 & w_1 & \\frac{1}{w_3 + 1} \\end{bmatrix} $\n",
        "\n",
        "This matrix provides the first-order partial derivatives of each component of $ f $ with respect to $ w_1, w_2, $ and $ w_3 $, offering insights into how the function $ f $ changes directionally in the 3-dimensional input space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definition 2.7 (Differntiability, multi-output case)\n",
        "To illustrate the concept of Fréchet differentiability for a multi-output function using Python, let's work with a specific example function and demonstrate how to verify its differentiability at a given point according to the definition you provided.\n",
        "\n",
        "Consider the function $ f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^2 $ defined by:\n",
        "$ f(w) = \\left[ \\begin{array}{c} f_1(w) \\\\ f_2(w) \\end{array} \\right] = \\left[ \\begin{array}{c} w_1^2 + w_2^2 \\\\ e^{w_1} + w_2^3 \\end{array} \\right] $\n",
        "where $ w = (w_1, w_2) $.\n",
        "\n",
        "The task is to verify that $ f $ is Fréchet differentiable at a particular point $ w $ (let's choose $ w = (1,1) $ for this example). According to the definition, we need to check that the limit of\n",
        "$ \\lim_{\\|v\\|_2 \\to 0} \\frac{\\|f(w + v) - f(w) - J(f)(w) \\cdot v\\|_2}{\\|v\\|_2} = 0 $\n",
        "where $ J(f)(w) $ is the Jacobian matrix of $ f $ at $ w $, and $ v $ is an arbitrary direction vector.\n",
        "\n",
        "We will compute this limit numerically for small values of $ \\|v\\|_2 $ to illustrate the concept of differentiability:\n",
        "\n",
        "1. Compute the Jacobian matrix $ J(f)(w) $ at $ w = (1,1) $.\n",
        "2. For a small vector $ v $, compute $ f(w + v) - f(w) - J(f)(w) \\cdot v $.\n",
        "3. Evaluate the limit by decreasing the magnitude of $ v $ and checking if the ratio approaches 0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1e-08, 3.36182359982022e-08),\n",
              " (1e-07, 2.8305653658042586e-07),\n",
              " (1e-06, 7.73154756903754e-07),\n",
              " (1e-05, 1.630950054524941e-05),\n",
              " (0.0001, 4.9290469680653423e-05),\n",
              " (0.001, 0.0020854235492624366),\n",
              " (0.01, 0.023653324274140474),\n",
              " (0.1, 0.15198962364614899),\n",
              " (1.0, 2.754513204551928)]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the function f and its Jacobian at w = (1, 1)\n",
        "def f(w):\n",
        "    return np.array([w[0]**2 + w[1]**2, np.exp(w[0]) + w[1]**3])\n",
        "\n",
        "def J(w):\n",
        "    return np.array([[2*w[0], 2*w[1]], [np.exp(w[0]), 3*w[1]**2]])\n",
        "\n",
        "w = np.array([1, 1])  # The point of interest\n",
        "\n",
        "# Function to check Fréchet differentiability\n",
        "def check_differentiability(w, epsilons):\n",
        "    results = []\n",
        "    for epsilon in epsilons:\n",
        "        # Generate a small vector v with a magnitude of epsilon\n",
        "        v = np.random.rand(2) * epsilon\n",
        "        v_norm = np.linalg.norm(v, 2)\n",
        "        \n",
        "        # Compute f(w + v) - f(w) - J(f)(w) * v\n",
        "        diff = f(w + v) - f(w) - J(w) @ v\n",
        "        \n",
        "        # Compute the ratio\n",
        "        ratio = np.linalg.norm(diff, 2) / v_norm\n",
        "        results.append((epsilon, ratio))\n",
        "    return results\n",
        "\n",
        "# Check differentiability for a range of epsilon values\n",
        "epsilons = np.logspace(-8, 0, 9)\n",
        "results = check_differentiability(w, epsilons)\n",
        "\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "Let's implement the steps in Python to demonstrate this:\n",
        "\n",
        "The results of the numerical check for Fréchet differentiability at $ w = (1,1) $ for our function $ f $ are given by the ratios of $\\|f(w + v) - f(w) - J(f)(w) \\cdot v\\|_2$ over $\\|v\\|_2$ for decreasing magnitudes of $ v $ (from $1e-08$ up to $1$). The ratios are as follows:\n",
        "\n",
        "- For $ \\epsilon = 1e-08 $, the ratio is approximately $ 3.23e-08 $.\n",
        "- For $ \\epsilon = 1e-07 $, the ratio is approximately $ 1.06e-07 $.\n",
        "- For $ \\epsilon = 1e-06 $, the ratio is approximately $ 2.68e-06 $.\n",
        "- For $ \\epsilon = 1e-05 $, the ratio is approximately $ 5.75e-06 $.\n",
        "- For $ \\epsilon = 0.0001 $, the ratio is approximately $ 1.40e-04 $.\n",
        "- For $ \\epsilon = 0.001 $, the ratio is approximately $ 6.86e-04 $.\n",
        "- For $ \\epsilon = 0.01 $, the ratio is approximately $ 2.79e-02 $.\n",
        "- For $ \\epsilon = 0.1 $, the ratio is approximately $ 9.81e-02 $.\n",
        "- For $ \\epsilon = 1.0 $, the ratio is approximately $ 2.18 $.\n",
        "\n",
        "As the magnitude of $ v $ decreases (i.e., as we approach $ 0 $), the ratio $\\frac{\\|f(w + v) - f(w) - J(f)(w) \\cdot v\\|_2}{\\|v\\|_2}$ tends to $ 0 $, illustrating the concept of Fréchet differentiability. Specifically, for very small values of $ \\epsilon $, the ratio is very close to $ 0 $, consistent with the definition of Fréchet differentiability, which requires this limit to be $ 0 $. This numerical example supports that the given function $ f $ is Fréchet differentiable at the point $ w = (1,1) $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definition 2.8 (Jacobian)\n",
        "To illustrate the concept of the Jacobian and how it can be used to compute the directional derivative of a function $ f: \\mathbb{R}^P \\rightarrow \\mathbb{R}^M $, let's consider a specific example function. We'll then use Python to compute its Jacobian and apply it to calculate the directional derivative along a given input direction $ v $.\n",
        "\n",
        "Let's define the function $ f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}^2 $ by:\n",
        "$ f(w) = \\left[ \\begin{array}{c} f_1(w) = w_1^2 + w_2^2 + w_3 \\\\ f_2(w) = e^{w_1} + w_2 \\cdot w_3 \\end{array} \\right] $\n",
        "where $ w = (w_1, w_2, w_3) $ is the input vector in $\\mathbb{R}^3$.\n",
        "\n",
        "The Jacobian of $ f $ at any point $ w $ is given by the matrix of all partial derivatives of $ f_1 $ and $ f_2 $ with respect to $ w_1, w_2, $ and $ w_3 $:\n",
        "$ \\partial f(w) = \\left[ \\begin{array}{ccc} \\frac{\\partial f_1}{\\partial w_1} & \\frac{\\partial f_1}{\\partial w_2} & \\frac{\\partial f_1}{\\partial w_3} \\\\ \\frac{\\partial f_2}{\\partial w_1} & \\frac{\\partial f_2}{\\partial w_2} & \\frac{\\partial f_2}{\\partial w_3} \\end{array} \\right] $\n",
        "\n",
        "We'll then compute the directional derivative of $ f $ at $ w $ along an input direction $ v = (v_1, v_2, v_3) $ using the formula:\n",
        "$ \\partial f(w)[v] = \\partial f(w) \\cdot v $\n",
        "\n",
        "Here's the Python code to compute the Jacobian and the directional derivative:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the function f\n",
        "def f(w):\n",
        "    return np.array([w[0]**2 + w[1]**2 + w[2], np.exp(w[0]) + w[1]*w[2]])\n",
        "\n",
        "# Define the Jacobian of f\n",
        "def J(w):\n",
        "    return np.array([\n",
        "        [2*w[0], 2*w[1], 1],\n",
        "        [np.exp(w[0]), w[2], w[1]]\n",
        "    ])\n",
        "\n",
        "# Compute the directional derivative of f at w along v\n",
        "def directional_derivative(w, v):\n",
        "    jacobian = J(w)\n",
        "    return np.dot(jacobian, v)\n",
        "\n",
        "# Example input\n",
        "w = np.array([1, 2, 3])  # Point of interest\n",
        "v = np.array([0.5, -1, 2])  # Direction vector\n",
        "\n",
        "# Compute the directional derivative\n",
        "dd = directional_derivative(w, v)\n",
        "\n",
        "dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "This code computes the Jacobian matrix of $ f $ at the point $ w = (1, 2, 3) $ and then uses it to calculate the directional derivative of $ f $ along the vector $ v = (0.5, -1, 2) $. Let's execute it and see the result.\n",
        "\n",
        "The directional derivative of the function $ f $ at the point $ w = (1, 2, 3) $ along the direction vector $ v = (0.5, -1, 2) $ is approximately $[-1, 2.35914091]$. This result is a vector in $\\mathbb{R}^2$ that indicates how the function $ f $ changes at the point $ w $ in the direction of $ v $."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNIeRuQ5YSQRhon3RVYFbUu",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
